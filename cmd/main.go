package main

import (
	"bufio"
	"context"
	"fmt"
	"log"
	"os"
	"strings"
	"time"

	"github.com/shouni/action-perfect-get-on-go/pkg/cleaner"
	"github.com/shouni/action-perfect-get-on-go/pkg/scraper"
	"github.com/shouni/action-perfect-get-on-go/pkg/types"

	"github.com/spf13/cobra"
)

// ----------------------------------------------------------------
// ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨åˆæœŸè¨­å®š (å¤‰æ›´ãªã—)
// ----------------------------------------------------------------

// ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
var llmAPIKey string
var llmTimeout time.Duration
var scraperTimeout time.Duration
var urlFile string

func init() {
	rootCmd.PersistentFlags().DurationVarP(&llmTimeout, "llm-timeout", "t", 5*time.Minute, "LLMå‡¦ç†ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“")
	rootCmd.PersistentFlags().DurationVarP(&scraperTimeout, "scraper-timeout", "s", 15*time.Second, "Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã®HTTPã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“")
	rootCmd.PersistentFlags().StringVarP(&llmAPIKey, "api-key", "k", "", "Gemini APIã‚­ãƒ¼ (ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ãŒå„ªå…ˆ)")
	rootCmd.PersistentFlags().StringVarP(&urlFile, "url-file", "f", "", "å‡¦ç†å¯¾è±¡ã®URLãƒªã‚¹ãƒˆã‚’è¨˜è¼‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
}

// ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
func main() {
	if err := rootCmd.Execute(); err != nil {
		os.Exit(1)
	}
}

var rootCmd = &cobra.Command{
	Use:   "action-perfect-get-on-go",
	Short: "è¤‡æ•°ã®URLã‚’ä¸¦åˆ—ã§å–å¾—ã—ã€LLMã§ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚",
	Long: `
å®Ÿè¡Œã«ã¯ã€-fã¾ãŸã¯--url-fileã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§URLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚
`,
	RunE: runMain,
}

// ----------------------------------------------------------------
// ãƒ¡ã‚¤ãƒ³ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼
// ----------------------------------------------------------------

// runMain ã¯ CLIã®ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—ã‚’ç®¡ç†ã™ã‚‹ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
func runMain(cmd *cobra.Command, args []string) error {
	// LLMå‡¦ç†ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ãƒ•ãƒ©ã‚°å€¤ã§è¨­å®š
	ctx, cancel := context.WithTimeout(cmd.Context(), llmTimeout)
	defer cancel()

	// 1. URLã®èª­ã¿è¾¼ã¿ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
	urls, err := generateURLs(urlFile)
	if err != nil {
		return err
	}
	log.Printf("ğŸš€ Action Perfect Get On: %då€‹ã®URLã®å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚", len(urls))

	// 2. Webã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å–å¾—ã¨ãƒªãƒˆãƒ©ã‚¤
	successfulResults, err := generateContents(ctx, urls, scraperTimeout)
	if err != nil {
		return err // å‡¦ç†å¯èƒ½ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã‚¼ãƒ­ã®å ´åˆã®ã‚¨ãƒ©ãƒ¼
	}

	// 3. AIã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨å‡ºåŠ›
	if err := generateCleanedOutput(ctx, successfulResults, llmAPIKey); err != nil {
		return err
	}

	return nil
}

// ----------------------------------------------------------------
// æŠ½å‡ºã•ã‚ŒãŸã‚¹ãƒ†ãƒƒãƒ—é–¢æ•° (ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼çš„ãªå½¹å‰²)
// ----------------------------------------------------------------

// generateURLs ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰URLã‚’èª­ã¿è¾¼ã¿ã€ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚
func generateURLs(filePath string) ([]string, error) {
	if filePath == "" {
		return nil, fmt.Errorf("å‡¦ç†å¯¾è±¡ã®URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚-f/--url-file ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§URLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
	}

	urls, err := readURLsFromFile(filePath)
	if err != nil {
		return nil, fmt.Errorf("URLãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: %w", err)
	}

	if len(urls) == 0 {
		return nil, fmt.Errorf("URLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«æœ‰åŠ¹ãªURLãŒä¸€ä»¶ã‚‚å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚")
	}
	return urls, nil
}

// generateContents ã¯URLã®ãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€ä¸¦åˆ—ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¨ãƒªãƒˆãƒ©ã‚¤ã‚’å®Ÿè¡Œã—ã€æˆåŠŸã—ãŸçµæœã®ã¿ã‚’è¿”ã—ã¾ã™ã€‚
func generateContents(ctx context.Context, urls []string, timeout time.Duration) ([]types.URLResult, error) {
	log.Println("--- 1. Webã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä¸¦åˆ—æŠ½å‡ºã‚’é–‹å§‹ ---")
	initialURLCount := len(urls)

	// ParallelScraperã®åˆæœŸåŒ–
	s, err := scraper.NewParallelScraper(timeout)
	if err != nil {
		return nil, fmt.Errorf("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: %w", err)
	}

	// ä¸¦åˆ—å®Ÿè¡Œ
	results := s.ScrapeInParallel(ctx, urls)

	// ç„¡æ¡ä»¶é…å»¶ (2ç§’)
	log.Println("ä¸¦åˆ—æŠ½å‡ºãŒå®Œäº†ã—ã¾ã—ãŸã€‚ã‚µãƒ¼ãƒãƒ¼è² è·ã‚’è€ƒæ…®ã—ã€æ¬¡ã®å‡¦ç†ã«é€²ã‚€å‰ã«2ç§’å¾…æ©Ÿã—ã¾ã™ã€‚")
	time.Sleep(2 * time.Second)

	// çµæœã®åˆ†é¡
	successfulResults, failedURLs := classifyResults(results)
	initialSuccessfulCount := len(successfulResults)

	// å¤±æ•—URLã®ãƒªãƒˆãƒ©ã‚¤å‡¦ç†
	if len(failedURLs) > 0 {
		retriedSuccessfulResults, retryErr := processFailedURLs(ctx, failedURLs, timeout)
		if retryErr != nil {
			log.Printf("WARNING: å¤±æ•—URLã®ãƒªãƒˆãƒ©ã‚¤å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: %v", retryErr)
		}
		// ãƒªãƒˆãƒ©ã‚¤ã§æˆåŠŸã—ãŸçµæœã‚’ãƒ¡ã‚¤ãƒ³ã®ãƒªã‚¹ãƒˆã«è¿½åŠ 
		successfulResults = append(successfulResults, retriedSuccessfulResults...)
	}

	// æœ€çµ‚æˆåŠŸæ•°ã®ãƒã‚§ãƒƒã‚¯
	if len(successfulResults) == 0 {
		return nil, fmt.Errorf("å‡¦ç†å¯èƒ½ãªWebã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä¸€ä»¶ã‚‚å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚URLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
	}

	// ãƒ­ã‚°å‡ºåŠ›
	log.Printf("æœ€çµ‚æˆåŠŸæ•°: %d/%d URL (åˆæœŸæˆåŠŸ: %d, ãƒªãƒˆãƒ©ã‚¤æˆåŠŸ: %d)",
		len(successfulResults), initialURLCount, initialSuccessfulCount, len(successfulResults)-initialSuccessfulCount)

	return successfulResults, nil
}

// generateCleanedOutput ã¯å–å¾—ã—ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’çµåˆã—ã€LLMã§ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ»æ§‹é€ åŒ–ã—ã¦å‡ºåŠ›ã—ã¾ã™ã€‚
func generateCleanedOutput(ctx context.Context, successfulResults []types.URLResult, apiKey string) error {
	// Cleanerã®åˆæœŸåŒ–
	// PromptBuilderã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãŸã‚ã€ã“ã“ã§ä¸€åº¦ã ã‘åˆæœŸåŒ–ã—å†åˆ©ç”¨ã—ã¾ã™ã€‚
	c, err := cleaner.NewCleaner()
	if err != nil {
		return fmt.Errorf("Cleanerã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: %w", err)
	}

	// ãƒ‡ãƒ¼ã‚¿çµåˆãƒ•ã‚§ãƒ¼ã‚º
	log.Println("--- 2. æŠ½å‡ºçµæœã®çµåˆ ---")
	combinedText := cleaner.CombineContents(successfulResults)
	log.Printf("çµåˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•: %dãƒã‚¤ãƒˆ", len(combinedText))

	// AIã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ•ã‚§ãƒ¼ã‚º (LLM)
	log.Println("--- 3. LLMã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨æ§‹é€ åŒ–ã‚’é–‹å§‹ (Go-AI-Clientåˆ©ç”¨) ---")
	cleanedText, err := c.CleanAndStructureText(ctx, combinedText, apiKey)
	if err != nil {
		return fmt.Errorf("LLMã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: %w", err)
	}

	// æœ€çµ‚çµæœã®å‡ºåŠ›
	fmt.Println("\n===============================================")
	fmt.Println("âœ… PERFECT GET ON: LLMã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¾Œã®æœ€çµ‚å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿:")
	fmt.Println("===============================================")
	fmt.Println(cleanedText)
	fmt.Println("===============================================")

	return nil
}

// ----------------------------------------------------------------
// ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (ãƒ­ã‚¸ãƒƒã‚¯ã¯å…ƒã®ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ãã®ã¾ã¾ç¶­æŒ)
// ----------------------------------------------------------------

// readURLsFromFile ã¯æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰URLã‚’èª­ã¿è¾¼ã¿ã€ã‚¹ãƒ©ã‚¤ã‚¹ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚
// ç©ºè¡Œã¨ã‚³ãƒ¡ãƒ³ãƒˆè¡Œï¼ˆ#ã‹ã‚‰å§‹ã¾ã‚‹ï¼‰ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚
func readURLsFromFile(filePath string) ([]string, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return nil, err
	}
	defer file.Close()

	var urls []string
	scanner := bufio.NewScanner(file)

	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())
		// ç©ºè¡Œã¨ã‚³ãƒ¡ãƒ³ãƒˆè¡Œï¼ˆ#ã§å§‹ã¾ã‚‹ï¼‰ã‚’ã‚¹ã‚­ãƒƒãƒ—
		if line == "" || strings.HasPrefix(line, "#") {
			continue
		}
		urls = append(urls, line)
	}

	if err := scanner.Err(); err != nil {
		return nil, fmt.Errorf("ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿å–ã‚Šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: %w", err)
	}

	return urls, nil
}

// classifyResults ã¯ä¸¦åˆ—æŠ½å‡ºã®çµæœã‚’æˆåŠŸã¨å¤±æ•—ã«åˆ†é¡ã—ã¾ã™ã€‚
func classifyResults(results []types.URLResult) (successfulResults []types.URLResult, failedURLs []string) {
	for _, res := range results {
		// ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã€ã¾ãŸã¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒç©ºã®å ´åˆã¯å¤±æ•—ã¨è¦‹ãªã™
		if res.Error != nil || res.Content == "" {
			failedURLs = append(failedURLs, res.URL)
		} else {
			successfulResults = append(successfulResults, res)
		}
	}
	return successfulResults, failedURLs
}

// formatErrorLog ã¯ã€å†—é•·ãªHTMLãƒœãƒ‡ã‚£ã‚’å«ã‚€ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰æƒ…å ±ã®ã¿ã«çŸ­ç¸®ã—ã¾ã™ã€‚
func formatErrorLog(err error) string {
	errMsg := err.Error()
	if idx := strings.Index(errMsg, ", ãƒœãƒ‡ã‚£: <!"); idx != -1 {
		errMsg = errMsg[:idx]
	}

	if idx := strings.LastIndex(errMsg, "æœ€çµ‚ã‚¨ãƒ©ãƒ¼:"); idx != -1 {
		return strings.TrimSpace(errMsg[idx:])
	}

	return errMsg
}

// processFailedURLs ã¯å¤±æ•—ã—ãŸURLã«å¯¾ã—ã¦5ç§’å¾…æ©Ÿå¾Œã€1å›ã ã‘é †æ¬¡ãƒªãƒˆãƒ©ã‚¤ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
func processFailedURLs(ctx context.Context, failedURLs []string, scraperTimeout time.Duration) ([]types.URLResult, error) {
	log.Printf("âš ï¸ WARNING: æŠ½å‡ºã«å¤±æ•—ã—ãŸURLãŒ %d ä»¶ã‚ã‚Šã¾ã—ãŸã€‚5ç§’å¾…æ©Ÿå¾Œã€é †æ¬¡ãƒªãƒˆãƒ©ã‚¤ã‚’é–‹å§‹ã—ã¾ã™ã€‚", len(failedURLs))
	time.Sleep(5 * time.Second) // ãƒªãƒˆãƒ©ã‚¤å‰ã®è¿½åŠ é…å»¶ (ã“ã“ã¯å¤‰æ›´ãªã—ã§5ç§’ç¶­æŒ)

	// ãƒªãƒˆãƒ©ã‚¤ç”¨ã®éä¸¦åˆ—ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
	retryScraperClient, err := scraper.NewClient(scraperTimeout)
	if err != nil {
		log.Printf("WARNING: ãƒªãƒˆãƒ©ã‚¤ç”¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: %vã€‚ãƒªãƒˆãƒ©ã‚¤å‡¦ç†ã¯å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã€‚", err)
		return nil, err // åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ã¯å‘¼ã³å‡ºã—å…ƒã«é€šçŸ¥
	}

	var retriedSuccessfulResults []types.URLResult
	log.Println("--- 1b. å¤±æ•—URLã®é †æ¬¡ãƒªãƒˆãƒ©ã‚¤ã‚’é–‹å§‹ ---")

	for _, url := range failedURLs {
		log.Printf("ãƒªãƒˆãƒ©ã‚¤ä¸­: %s", url)

		// é †æ¬¡å†è©¦è¡Œ (éä¸¦åˆ—)
		content, err := retryScraperClient.ExtractContent(url, ctx)

		if err != nil || content == "" {
			formattedErr := formatErrorLog(err)
			log.Printf("âŒ ERROR: ãƒªãƒˆãƒ©ã‚¤ã§ã‚‚ %s ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: %s", url, formattedErr)
		} else {
			log.Printf("âœ… SUCCESS: %s ã®æŠ½å‡ºãŒãƒªãƒˆãƒ©ã‚¤ã§æˆåŠŸã—ã¾ã—ãŸã€‚", url)
			retriedSuccessfulResults = append(retriedSuccessfulResults, types.URLResult{
				URL:     url,
				Content: content,
				Error:   nil,
			})
		}
	}
	return retriedSuccessfulResults, nil
}
